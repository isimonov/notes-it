Apache Kafka — распределённый программный брокер сообщений с открытым исходным кодом, разрабатываемый в рамках фонда Apache на языках Java и Scala.

Фундаментальное отличие Kafka от очередей состоит в том, как сообщения хранятся на брокере и как потребляются консьюмерами.

- Сообщения в Kafka **не удаляются** брокерами по мере их обработки консьюмерами — данные в Kafka могут храниться днями, неделями, годами.
- Благодаря этому одно и то же сообщение может быть обработано **сколько угодно раз** разными консьюмерами и в разных контекстах.

В этом кроется главная мощь и главное отличие Kafka от традиционных систем обмена сообщениями. Отсюда вытекает особенность работы с топиками. Очередей как таковых в Kafka нет. Те проблемы которые решает очередь в традиционных брокерах сообщений, в Kafka решает консьюмер группа.

# Topics

Сообщения в Kafka организованы и хранятся в именованных топиках (Topics). В топики публикуют продюссеры, читают консьюмеры в рамках комнсьюмер групп.

# Partitions

Каждый топик состоит из одной и более партиций (Partition), распределённых между брокерами внутри одного кластера. Подобная распределённость важна для горизонтального масштабирования кластера, так как она позволяет клиентам писать и читать сообщения с нескольких брокеров одновременно.

Когда новое сообщение добавляется в топик, на самом деле оно записывается в одну из партиций этого топика. Сообщения с одинаковыми ключами всегда записываются в одну и ту же партицию, тем самым гарантируя очередность или порядок записи и чтения.

Сообщения не удаляются из лога после передачи консьюмерам и могут быть вычитаны сколько угодно раз. Время гарантированного хранения данных на брокере можно контролировать с помощью специальных настроек. Длительность хранения сообщений при этом не влияет на общую производительность системы. Поэтому совершенно нормально хранить сообщения в Kafka днями, неделями, месяцами или даже годами.

# Replica

Для гарантии сохранности данных каждая партиция в Kafka может быть реплицирована n раз, где n — replication factor. Таким образом гарантируется наличие нескольких копий сообщения, хранящихся на разных брокерах.

У каждой партиции есть «лидер» (Leader) — брокер, который работает с клиентами. Именно лидер работает с продюсерами и в общем случае отдаёт сообщения консьюмерам. К лидеру осуществляют запросы фолловеры (Follower) — брокеры, которые хранят реплику всех данных партиций. Сообщения всегда отправляются лидеру и, в общем случае, читаются с лидера.

Чтобы понять, кто является лидером партиции, перед записью и чтением клиенты делают запрос метаданных от брокера. Причём они могут подключаться к любому брокеру в кластере.

Основная структура данных в Kafka — это распределённый, реплицируемый лог. Каждая партиция — это и есть тот самый реплицируемый лог, который хранится на диске. Каждое новое сообщение, отправленное продюсером в партицию, сохраняется в «голову» этого лога и получает свой уникальный, монотонно возрастающий offset (64-битное число, которое назначается самим брокером).

# Consumer Groups

Топик может быть разделен на разделы, которые представляют собой логи только для добавления, где хранятся сообщения. Это позволяет размещать каждый топик и реплицировать его между несколькими брокерами. Потребительские группы в Kafka имеют следующие особенности:

- id — номер группы, который присваивается ей при создании для возможности подключения потребителей, использующих в качестве параметра соединения этот идентификатор (id). Следовательно, для параллельного использования группы, потребители используют один и тот же group.id.
- Брокер Kafka назначает разделы топика потребителю в группе таким образом, что каждый раздел потребляется ровно одним потребителем в группе. Если консьюмеров в группе окажется больше количества партиций, то эта превышающая от общего количества часть консьюмеров не будет получать сообщения.
- Потребители видят сообщение в том порядке, в котором они были сохранены в журнале, независимо от того, в какой момент времени они подключились к группе.


# Apache ZooKeeper

ZooKeeper выполняет роль консистентного хранилища метаданных и распределённого сервиса логов. Именно он способен сказать, живы ли ваши брокеры, какой из брокеров является контроллером (то есть брокером, отвечающим за выбор лидеров партиций), и в каком состоянии находятся лидеры партиций и их реплики.

# KRaft

Начиная с Kafka 3.3.1 роль консистентного хранилища метаданных стал выполнять KRaft. Новый контроллер лога метаданных использует алгоритм репликации Raft, который требует подтверждения от кворума, а не от всех узлов. 

Использование KRaft вместо ZooKeeper:

- Позволило иметь больше синхронизированных реплик для этого важного лога метаданных, чтобы повысить доступность;
- Снизить задержки при добавлении записей в лог метаданных

# Семантики доставки

Семантика доставки позволяет задать баланс между скоростью доставки и расходами на надёжность.

1. exactly-once — подход, при котором сообщение доставляется получателю строго один раз, без дублирования и потери данных.
2. at-most-once — сообщение будет доставлено получателю не более одного раза, но может не быть доставлено вовсе.
3. at-least-once — сообщение будет доставлено как минимум один раз, но возможно дублирование данных в результате повторной отправки.

На первый взгляд самой правильной для любого приложения кажется семантика exactly once, однако это не всегда так. Например, при передаче партнёрских координат вовсе не обязательно сохранять каждую точку из них, и вполне хватит at-most once. А при обработке идемпотентных событий нас вполне может и устроить дубль, если статусная модель предполагает его корректную обработку.

В распределённых системах у exactly-once есть своя цена: высокая надёжность означает большие задержки. Рассмотрим, какие инструменты предлагает Kafka для реализации всех трёх семантик доставки сообщений в брокер.

# Надёжность доставки

Со стороны продюсера разработчик определяет надёжность доставки сообщения до Kafka с помощью параметра **_acks_**.

- Указывая **_0_** или **_none_**, продюсер будет отправлять сообщения в Kafka, не дожидаясь никаких подтверждений записи на диск со стороны брокера. Это самая слабая гарантия. В случае выхода брокера из строя или сетевых проблем, вы так и не узнаете, попало сообщение в лог или просто потерялось.
- Указывая настройку в **_1_** или **_leader_**, продюсер при записи будет дожидаться ответа от брокера с лидерской партицией — значит, сообщение сохранено на диск одного брокера. В этом случае вы получаете гарантию, что сообщение было получено по крайней мере один раз, но это всё ещё не страхует вас от проблем в самом кластере. Это может случится когда брокер с лидерской партиции выходит из строя, а фолловеры не успели отреплицировать с него данные.
- устанавливая acks в **_-1_** или **_all_**, вы просите брокера с лидерской партицией отправить вам подтверждение только тогда, когда запись попадёт на локальный диск брокера и в реплики-фолловеры. Число этих реплик устанавливает настройка **_min.insync.replicas_**. Лучше устанавливать _min.insync.replicas_ на единицу меньше числа реплик, иначе в случае выхода из строя брокера и потери одной реплики продюсер больше не сможет записывать сообщение в кластер, поскольку не дождётся подтверждения.

# Идемпотентные продюсеры

C выбором **_acks=all_** возможны дубликаты сообщений. Если брокер не смог отправить подтверждение продюсеру из-за сетевых проблем? В таком случае, продюсер повторно отправляет сообщение брокеру. Брокер послушно сохраняет добавляет ещё одно сообщение в лог — появляется дубликат.

Эта проблема решается в Kafka благодаря транзакционному API и использованию идемпотентности. В брокере есть специальная опция, которая включает идемпотентность — **_enable.idempotence_**. Так каждому сообщению будет проставлен идентификатор продюсера или PID и монотонно увеличивающийся sequence number. За счёт этого сообщения-дубликаты от одного продюсера с одинаковым PID будут отброшены на стороне брокера.

Если говорить проще — когда вы используете _acks=all_, нет никаких причин не включать _enable.idempotence_ для своих продюсеров. Так вы добьётесь гарантии exactly once при записи в брокер и избежите дубликатов. Но у этого могущества есть своя цена — запись будет идти дольше.


[Apache Kafka: основы технологии](https://habr.com/ru/companies/slurm/articles/550934/)

[Kafka за 20 минут](https://habr.com/ru/companies/sbermarket/articles/738634/)